{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "  Downloading transformers-4.39.2-py3-none-any.whl.metadata (134 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m2.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting datasets\r\n",
      "  Using cached datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting filelock (from transformers)\r\n",
      "  Using cached filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\r\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from transformers) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Collecting regex!=2019.12.17 (from transformers)\r\n",
      "  Downloading regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\r\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.7 kB)\r\n",
      "Collecting safetensors>=0.4.1 (from transformers)\r\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from transformers) (4.66.2)\r\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\r\n",
      "  Downloading pyarrow-15.0.2-cp310-cp310-macosx_10_15_x86_64.whl.metadata (3.0 kB)\r\n",
      "Collecting pyarrow-hotfix (from datasets)\r\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\r\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting pandas (from datasets)\r\n",
      "  Downloading pandas-2.2.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (19 kB)\r\n",
      "Collecting xxhash (from datasets)\r\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess (from datasets)\r\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets)\r\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting aiohttp (from datasets)\r\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.4 kB)\r\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\r\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\r\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\r\n",
      "  Downloading multidict-6.0.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (4.2 kB)\r\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\r\n",
      "  Downloading yarl-1.9.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (31 kB)\r\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\r\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Downloading transformers-4.39.2-py3-none-any.whl (8.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.8/8.8 MB\u001B[0m \u001B[31m5.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached datasets-2.18.0-py3-none-any.whl (510 kB)\r\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\r\n",
      "Downloading aiohttp-3.9.3-cp310-cp310-macosx_10_9_x86_64.whl (397 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m397.9/397.9 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m388.9/388.9 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pyarrow-15.0.2-cp310-cp310-macosx_10_15_x86_64.whl (27.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m27.2/27.2 MB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl (296 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m296.4/296.4 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading safetensors-0.4.2-cp310-cp310-macosx_10_12_x86_64.whl (426 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m426.3/426.3 kB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tokenizers-0.15.2-cp310-cp310-macosx_10_12_x86_64.whl (2.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.6/2.6 MB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached filelock-3.13.3-py3-none-any.whl (11 kB)\r\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pandas-2.2.1-cp310-cp310-macosx_10_9_x86_64.whl (12.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.5/12.5 MB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
      "Downloading xxhash-3.4.1-cp310-cp310-macosx_10_9_x86_64.whl (31 kB)\r\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\r\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl (53 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.8/53.8 kB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading multidict-6.0.5-cp310-cp310-macosx_10_9_x86_64.whl (30 kB)\r\n",
      "Downloading yarl-1.9.4-cp310-cp310-macosx_10_9_x86_64.whl (81 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m81.2/81.2 kB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: xxhash, safetensors, regex, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, filelock, dill, async-timeout, yarl, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\r\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.18.0 dill-0.3.8 filelock-3.13.3 frozenlist-1.4.1 fsspec-2024.2.0 huggingface-hub-0.22.2 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.1 pyarrow-15.0.2 pyarrow-hotfix-0.6 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.39.2 xxhash-3.4.1 yarl-1.9.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets\n",
    "!pip install rouge.score nltk py7zr\n",
    "!pip install accelerate\n",
    "!pip install pytorch-accelerated\n",
    "!pip install transformers==4.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/davidlee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "import transformers\n",
    "\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "\n",
    "nltk.download('punkt')\n",
    "torch.mps.set_per_process_memory_fraction(0.0) # Train on Macbook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/14732 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4c2ddb15bc44bffbfda888012b177be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/819 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f2c25f88d0b4cde961d07cdfabc86b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/818 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae9c8ff6a16c4deda9bac2adb347c693"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset('samsum')\n",
    "data.save_to_disk('/Users/davidlee/PycharmProjects/KoodooProject/koodoovoice/dataset_temp/samsum')\n",
    "data = load_from_disk(\"/Users/davidlee/PycharmProjects/KoodooProject/koodoovoice/dataset_temp/samsum\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2l/k2m1kf8908q92grpmz923f600000gn/T/ipykernel_3882/100593241.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('rouge')\n",
      "/Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d491d0770614ebdbcf6b77e23210c25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric('rouge')\n",
    "model_checkpoints = 'kabita-choudhary/finetuned-bart-for-conversation-summary'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "max_input = 512\n",
    "max_target = 128\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoints)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "  inputs = [dialogue for dialogue in data_to_process['dialogue']]\n",
    "  model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(data_to_process['summary'], max_length=max_target, padding='max_length', truncation=True)\n",
    "\n",
    "  model_inputs['labels'] = targets['input_ids']\n",
    "  return model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/819 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e34e1f0539e4f64a517406da5feb157"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/KoodooProject/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenize_data = data.map(preprocess_data, batched = True, remove_columns=['id', 'dialogue', 'summary'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "train_sample = tokenize_data['train'].shuffle(seed=123).select(range(2000))\n",
    "validation_sample = tokenize_data['validation'].shuffle(seed=123).select(range(800))\n",
    "test_sample = tokenize_data['test'].shuffle(seed=123).select(range(800))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "tokenize_data['train'] = train_sample\n",
    "tokenize_data['validation'] = validation_sample\n",
    "tokenize_data['test'] = test_sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "collator = transformers.DataCollatorForSeq2Seq(tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def compute_rouge(pred):\n",
    "  predictions, labels = pred\n",
    "  #decode the predictions\n",
    "  decode_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "  #decode labels\n",
    "  decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "  #compute results\n",
    "  res = metric.compute(predictions=decode_predictions, references=decode_labels, use_stemmer=True)\n",
    "  #get %\n",
    "  res = {key: value.mid.fmeasure * 100 for key, value in res.items()}\n",
    "\n",
    "  pred_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "  res['gen_len'] = np.mean(pred_lens)\n",
    "\n",
    "  return {k: round(v, 4) for k, v in res.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "args = transformers.Seq2SeqTrainingArguments(\n",
    "    'conversation-summ',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size= 1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    eval_accumulation_steps=1,\n",
    "    fp16=False,\n",
    "    use_mps_device=True,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "trainer = transformers.Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenize_data['train'],\n",
    "    eval_dataset=tokenize_data['validation'],\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_rouge\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}